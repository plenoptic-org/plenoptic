name: build
on:
  workflow_dispatch:
  schedule:
  - cron: 0 0 * * 0     # weekly
  pull_request:
    branches:
    - main

jobs:
  # based on https://slashgear.github.io/how-to-split-test-by-folder-with-github-action/
  notebooks:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.7, 3.8, 3.9, '3.10']
      fail-fast: false
    name: Execute notebooks
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: pip
        cache-dependency-path: setup.py
    - name: Setup FFmpeg
      uses: FedericoCarboni/setup-ffmpeg@v3.1
    - name: Install dependencies
      run: |
        pip install --upgrade --upgrade-strategy eager .[dev,nb] papermill
    - name: Download TID2013 dataset
      run: |
        mkdir -p data
        wget https://osf.io/7nfkz/download -O ./data/tid2013.rar
        7z x ./data/tid2013.rar -o./data/tid2013/
    - name: Download Portilla-Simoncelli data
      run: |
        wget https://osf.io/eqr3t/download -O ./data/portilla_simoncelli_images.tar.gz
        tar xfz ./data/portilla_simoncelli_images.tar.gz --directory=./data/
    - name: Run notebooks
      if: ${{ !contains(fromJSON('["examples/Demo_Eigendistortion.ipynb", "examples/Metamer-Portilla-Simoncelli.ipynb"]'), matrix.notebook) }}
      run: |
        for file in examples/*ipynb; do
           # these first two notebooks take much longer than the rest to run (2
           # and 1 hours on laptop, respectively, longer on runners). So we use
           # papermill's parameters to reduce the max number of steps for
           # synthesis in them (we want to test that each cell runs, but we
           # don't need synthesis to go to completion).
           if [[ "$file" =~ "Metamer-Portilla-Simoncelli" ]]; then
              papermill $file $file_output.ipynb -p short_synth_max_iter 10 -p long_synth_max_iter 10 -p longest_synth_max_iter 10 -k python3 --cwd examples/
           elif [[ "$file" =~ "Demo_Eigendistortion" ]]; then
              papermill $file $file_output.ipynb -p max_iter_frontend 10 -p max_iter_vgg 10 -k python3 --cwd examples/
           else
              jupyter execute $file --kernel_name=python3
            fi
        done
  tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.7, 3.8, 3.9, '3.10']
      fail-fast: false
    name: Run pytest scripts
    steps:
    - uses: actions/checkout@v4
    - name: Install Python 3
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: pip
        cache-dependency-path: setup.py
    - name: Install dependencies
      run: |
        # using the --upgrade and --upgrade-strategy eager flags ensures that
        # pip will always install the latest allowed version of all
        # dependencies, to make sure the cache doesn't go stale
        pip install --upgrade --upgrade-strategy eager .[dev]
    - name: Run tests with pytest
      run: |
        pytest -n auto --cov-report xml
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@7598e39340e1dff4d6ebf7cf07a5e8184bde67e7 # v4.0.1
  all_tutorials_in_docs:
    runs-on: ubuntu-latest
    name: Check that all tutorial notebooks are included in docs
    steps:
    - uses: actions/checkout@v4
    - name: Check for file
      shell: bash
      # there are two levels that the notebooks can be in
      run: |
        for file in examples/*ipynb; do
           if [[ -z "$(grep $file docs/tutorials/*nblink)" && -z "$(grep $file docs/tutorials/*/*nblink)" ]] ; then
              exit 1
           fi
        done
  no_extra_nblinks:
    runs-on: ubuntu-latest
    name: Check that we don't have any extra nblink files
    steps:
    - uses: actions/checkout@v4
    - name: Check same number of nblink and notebooks
      shell: bash
      run: |
        n_nblink=0; for file in docs/tutorials/*nblink; do let "n_nblink+=1"; done;
        for file in docs/tutorials/*/*nblink; do let "n_nblink+=1"; done;
        n_ipynb=0; for file in examples/*ipynb; do let "n_ipynb+=1"; done;
        if [[ $n_nblink != $n_ipynb ]]; then exit 1; fi;
  check_urls:
    runs-on: ubuntu-latest
    name: Check all urls are valid
    steps:
    - uses: actions/checkout@v4
      # there are several cells in the notebook whose output includes links that
      # urlchecker htinks are invalid (though when I check them manually, they
      # look fine). Regardless, they're unimportant -- they're part of warning
      # messages and similar, so we don't want to check them.
    - name: strip notebook output
      run: |
        pip install nbstripout
        nbstripout examples/*ipynb
    - uses: urlstechie/urlchecker-action@b643b43e2ac605e1475331c7b67247d242b7dce4 # 0.0.34
      with:
        file_types: .md,.py,.rst,.ipynb
        print_all: false
        timeout: 5
        retry_count: 3

  check:
    if: always()
    needs:
    - notebooks
    - tests
    - all_tutorials_in_docs
    - no_extra_nblinks
    - check_urls
    runs-on: ubuntu-latest
    steps:
    - name: Decide whether all tests and notebooks succeeded
      uses: re-actors/alls-green@afee1c1eac2a506084c274e9c02c8e0687b48d9e # v1.2.2
      with:
        jobs: ${{ toJSON(needs) }}
